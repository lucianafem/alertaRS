{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15EpwCtoi1kA-yIFepYInuUqa6oseAxTp",
      "authorship_tag": "ABX9TyMU4i+AVo0J+s8i3lm9kOPH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucianafem/alertaRS/blob/main/alertaRS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1QkUSA56842"
      },
      "outputs": [],
      "source": [
        "%pip install -q google-colab-selenium\n",
        "!pip install -q -U google-generativeai\n",
        "!pip freeze > requirements.txt\n",
        "\n",
        "import google.generativeai as genai\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "import seaborn as sn\n",
        "from prettytable import PrettyTable\n",
        "import google_colab_selenium as gs\n",
        "import re\n",
        "import random\n",
        "from random import randint\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key= userdata.get('SECRET_KEY')\n",
        "api_key= api_key\n",
        "\n",
        "#GOOGLE_API_KEY=\n",
        "#genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "generation_config = {\n",
        "  \"candidate_count\": 1,\n",
        "  \"temperature\": 0.5,\n",
        "}\n",
        "\n",
        "safety_settings={\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'SEXUAL' : 'BLOCK_NONE',\n",
        "    'DANGEROUS' : 'BLOCK_NONE'\n",
        "    }\n",
        "\n",
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                                  generation_config=generation_config,\n",
        "                                  safety_settings=safety_settings,)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/imersaoiadados.xlsx'\n",
        "data = pd.read_excel(path)"
      ],
      "metadata": {
        "id": "6sFxSq7t7e2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "\n",
        "X_train0= data.iloc[0:,1:4]\n",
        "y_train0= data.iloc[0:,4:5]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train0 = scaler.fit_transform(X_train0)\n",
        "\n",
        "labelencoder_classe = LabelEncoder()\n",
        "y_train0 = labelencoder_classe.fit_transform(y_train0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train0, y_train0, test_size=0.35, random_state=0) # separa o X_train para treinar\n",
        "# print(len(X_train),len(X_test)) # 65 e 35. A matriz de confusão deverão somar 35 objetos.\n",
        "\n",
        "NN = Sequential()\n",
        "NN.add(Dense(8,input_dim=3, activation='tanh'))\n",
        "NN.add(Dense(10, activation='tanh'))\n",
        "NN.add(Dense(10, activation='tanh'))\n",
        "NN.add(Dense(6, activation='softmax'))\n",
        "NN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "t2 = time.time()\n",
        "def accuracyscore(classificador,X_train, X_test, y_train,y_test):\n",
        "    t3 = time.time()\n",
        "    classificador.fit(X_train,y_train,epochs=1000,verbose=0)\n",
        "    y_predictions= classificador.predict(X_test)\n",
        "    y_predictions= np.argmax(y_predictions,axis=1)\n",
        "\n",
        "    ExecTimeClassificador= round((time.time()) - t3 + (t2-t1),2)\n",
        "\n",
        "    accuracyscore = accuracy_score(y_test, y_predictions)\n",
        "    confusionmatrix=confusion_matrix(y_test, y_predictions)\n",
        "\n",
        "    return (round(accuracyscore,2),confusionmatrix,ExecTimeClassificador)\n",
        "\n",
        "NeuralNetworkdef= accuracyscore(NN,X_train,X_test,y_train,y_test)\n",
        "NeuralNetwork_score= NeuralNetworkdef[0]\n",
        "NeuralNetwork_cm= NeuralNetworkdef[1]\n",
        "NeuralNetwork_time= NeuralNetworkdef[2]\n",
        "\n",
        "print('NeuralNetwork_score=', NeuralNetwork_score)\n",
        "\n",
        "print('NeuralNetwork_cm=', NeuralNetwork_cm)\n",
        "\n",
        "print('Execution Time Neural Network (s) =', NeuralNetwork_time)\n",
        "\n",
        "x = PrettyTable()\n",
        "column_names = [\"Machine Learning\", \"Score\"]\n",
        "\n",
        "x.add_column(column_names[0], [\"Neural Network\"])\n",
        "x.add_column(column_names[1], [NeuralNetwork_score])\n",
        "print(x)\n",
        "\n",
        "x = PrettyTable()\n",
        "column_names = [\"Machine Learning\", \"Confusion Matrix\"]\n",
        "\n",
        "x.add_column(column_names[0], [\"Neural Network\"])\n",
        "x.add_column(column_names[1], [NeuralNetwork_cm])\n",
        "print(x)\n",
        "\n",
        "x = PrettyTable()\n",
        "column_names = [\"Machine Learning\", \"Time (s)\"]\n",
        "\n",
        "x.add_column(column_names[0], [\"Neural Network\"])\n",
        "x.add_column(column_names[1], [NeuralNetwork_time])\n",
        "print(x)\n",
        "\n",
        "cfm= NeuralNetwork_cm\n",
        "classes= [\"0\",\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
        "df_cfm= pd.DataFrame(cfm, index = classes, columns = classes)\n",
        "plt.figure(figsize = (10,7))\n",
        "cfm_plot= sn.heatmap(df_cfm, annot=True,fmt='.3g')  # 3g para colocar os numeros em float\n",
        "cfm_plot.figure.savefig(\"cfm.png\")\n",
        "\n",
        "x= [\"Neural Network\"]\n",
        "\n",
        "y=[NeuralNetwork_score]\n",
        "\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.bar(x,y,color = '0.40', width = 0.25)  # coloca em um nivel de cinza\n",
        "plt.xlabel('Machine Learning')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(rotation=60)\n",
        "for index, value in enumerate(y):\n",
        "    plt.text(index-0.15,value+0.009, str(value),weight=\"bold\")\n",
        "plt.title('Accuracy -  Neural Network')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Yi4YcsTG7jmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clas= data.iloc[0:6,6:7]\n",
        "rec= data.iloc[0:6,7:8]\n",
        "\n",
        "driver = gs.Chrome()\n",
        "driver.get('https://www.climatempo.com.br/previsao-do-tempo/15-dias/cidade/363/portoalegre-rs')\n",
        "p= driver.find_element(\"xpath\",'//*[@id=\"first-block-of-days\"]/div[4]/section[1]/div[3]/div/div[3]/div[2]/div/div/span').text.strip()\n",
        "p= int(re.findall(r'([\\d:,.]+)',p)[0])  # procura numeros\n",
        "driver.quit()\n",
        "n= round(random.uniform(1, 5.3),1)\n",
        "v= randint(4000, 5000)\n",
        "print(f'A precipitação prevista para hoje é de {p} mm. O nível do Guaíba está em {n} m. A velocidade medida é {v} (m/s).')\n",
        "X_predict= np.array([[p,n,v]])\n",
        "y_predict= NN.predict(X_predict)\n",
        "y_predict= np.argmax(y_predict,axis=1)\n",
        "\n",
        "index= clas.index.get_loc(y_predict[0])\n",
        "recom= rec.iloc[index]['recomendacao']\n",
        "print(f'Classificação: {y_predict[0]} \\n. Recomendação: {recom}.')\n"
      ],
      "metadata": {
        "id": "HgE5MJKm7z6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pais= input(\"País: \")\n",
        "estado= input(\"Estado: \")\n",
        "cidade= input(\"Cidade: \")\n",
        "\n",
        "def busca_ajuda(pais,estado,cidade):\n",
        "  prompt = f'Procure no {pais} na cidade de {cidade} dentro do estado {estado} os 5 maiores hospitais que atendem \\\n",
        "            em caso de emergência. Mostre o endereço e o telefone de cada hospital.\\\n",
        "            Liste os cinco maiores pontos de abrigo.Mostre o endereço e o telefone de abrigo.\\\n",
        "            Liste as 5 ONGs que poderiam ajudar.Mostre o endereço e o telefone de cada ONG.'\n",
        "  response = model.generate_content(prompt)\n",
        "  ajuda= response.text.split(\"/n\")\n",
        "  return ajuda\n",
        "\n",
        "ajuda=busca_ajuda(pais,estado,cidade)\n",
        "\n",
        "for i in ajuda:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "JXHTqe1BmBPv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}